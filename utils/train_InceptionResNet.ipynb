{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.efficientnet_v2 import EfficientNetV2B3\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras import layers\n",
    "import os.path\n",
    "from tensorflow import data as tf_data"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "IMAGE_SIZE = 224  # Input size for EfficientNetB0\n",
    "MODEL_FILE = \"model_eff.h5\"\n",
    "train = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"split_data/train\",\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    label_mode='int',\n",
    "    shuffle=True\n",
    ")\n",
    "val = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    \"split_data/val\",\n",
    "    image_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "    batch_size=32,\n",
    "    label_mode='int',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "class_names = train.class_names # ['Pallas_cats', 'Persian_cats', 'Ragdolls', 'Singapura_cats', 'Sphynx_cats']\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "augmentation = tf.keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.2),\n",
    "    layers.RandomZoom(0.2),\n",
    "    layers.RandomContrast(0.2)\n",
    "])\n",
    "\n",
    "\n",
    "def preprocess(x, y, train):\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    x = preprocess_input(x)  # EfficientNetB0 specific preprocessing\n",
    "    if train:\n",
    "        x = augmentation(x)  # Apply data augmentation\n",
    "    return x, y"
   ],
   "id": "ef34cb7e738a1f15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "train_generator = train.map(lambda x, y: preprocess(x, y, True)).prefetch(buffer_size=AUTOTUNE)\n",
    "val_generator = val.map(lambda x, y: preprocess(x, y, False)).prefetch(buffer_size=AUTOTUNE)"
   ],
   "id": "13af19d834ef24f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def create_model(num_classes):\n",
    "    base_model = EfficientNetB0(\n",
    "        weights='imagenet',\n",
    "        include_top=False,\n",
    "        input_shape=(IMAGE_SIZE, IMAGE_SIZE, 3)\n",
    "    )\n",
    "    base_model.trainable = False  # 初始冻结基础模型\n",
    "\n",
    "    inputs = tf.keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "    x = preprocess_input(inputs)  # 关键：使用专用预处理\n",
    "    x = base_model(x, training=False)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ],
   "id": "8f5b4ed93ee7b3cd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def load_existing(model_file):\n",
    "    model = load_model(model_file)\n",
    "    # 解冻最后4个块进行微调\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.Model):  # 找到基础模型\n",
    "            base_model = layer\n",
    "            break\n",
    "\n",
    "    if base_model:\n",
    "        # 解冻最后4个块\n",
    "        for layer in base_model.layers[-20:]:\n",
    "            if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.trainable = True\n",
    "    return model\n"
   ],
   "id": "d6bf36bbcbe11025"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def train(model_file, train_path, validation_path, num_classes=5, steps=100, num_epochs=20):\n",
    "    if os.path.exists(model_file):\n",
    "        print(\"\\n*** Loading existing model ***\\n\")\n",
    "        model = load_existing(model_file)\n",
    "        # 必须重新编译\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=1e-4),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "    else:\n",
    "        print(\"\\n*** Creating new model ***\\n\")\n",
    "        model = create_model(num_classes)\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=1e-3),\n",
    "            loss='sparse_categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "\n",
    "    checkpoint = ModelCheckpoint(\n",
    "        model_file,\n",
    "        save_best_only=True,\n",
    "        monitor='val_accuracy',\n",
    "        mode='max'\n",
    "    )\n",
    "\n",
    "    # 第一阶段：训练新添加的层\n",
    "    print(\"=== Phase 1: Training Head ===\")\n",
    "    history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps,\n",
    "        epochs=num_epochs,\n",
    "        callbacks=[checkpoint],\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=20\n",
    "    )\n",
    "\n",
    "    # 第二阶段：微调\n",
    "    print(\"\\n=== Phase 2: Fine-Tuning ===\")\n",
    "    # 找到基础模型并解冻部分层\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.Model):\n",
    "            base_model = layer\n",
    "            break\n",
    "\n",
    "    if base_model:\n",
    "        base_model.trainable = True\n",
    "        # 解冻最后4个块 (EfficientNetB0有7个块，解冻block5b到block7a)\n",
    "        for layer in base_model.layers:\n",
    "            layer.trainable = False  # 先冻结所有\n",
    "\n",
    "        # 解冻最后部分层\n",
    "        for layer in base_model.layers[-20:]:\n",
    "            if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "                layer.trainable = True\n",
    "\n",
    "    # 使用更小的学习率\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=1e-5),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=steps,\n",
    "        epochs=num_epochs,\n",
    "        callbacks=[checkpoint],\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=20\n",
    "    )\n"
   ],
   "id": "db87d497dcda0176"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def main():\n",
    "    train(\n",
    "        MODEL_FILE,\n",
    "        train_path=\"split_data/train\",\n",
    "        validation_path=\"split_data/val\",\n",
    "        steps=100,  # 根据数据集大小调整\n",
    "        num_epochs=15\n",
    "    )\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ],
   "id": "e60729294ae140c1"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
